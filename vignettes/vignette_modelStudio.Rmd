---
title: "modelStudio - perks and features"
author: "Hubert Baniecki"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{modelStudio - perks and features}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = FALSE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)
```

`modelStudio::modelStudio` computes various (instance and dataset level) model explanations and produces an interactive, customizable dashboard made with D3.js. It consists of multiple panels for plots with their short descriptions. Easily save and share the dashboard with others. Tools for model exploration unite with tools for EDA (Exploratory Data Analysis) to give a broad overview of the model behavior.

Let's use `DALEX::HR` dataset to explore `modelStudio` parameters:

```{r results="hide"}
train <- DALEX::HR[1:100,]
train$fired <- ifelse(train$status == "fired", 1, 0)
train <- train[,-6]

head(train)
```

```{r echo = FALSE, fig.align='center'}
knitr::kable(head(train), digits = 2, caption = "DALEX::HR dataset")
```

Prepare data and model for the explainer:

```{r results="hide", eval = FALSE}
# create a random forest model
library("randomForest")
model <- randomForest(fired ~., data = train)

# prepare validation dataset
test <- DALEX::HR_test[1:100,]
test$fired <- ifelse(test$status == "fired", 1, 0)
test <- test[,-6]

# create an explainer
explainer <- DALEX::explain(model = model,
                            data = test,
                            y = test$fired)

# start modelStudio
library("modelStudio")
```

-------------------------------------------------------------------

## modelStudio parameters

### instance explanations

Pass data points to `new_observation` parameter for instance explanations
such as Break Down, Shapley Values and Ceteris Paribus Profiles. Use `new_observation_y`
to show their true labels.

```{r eval = FALSE}
new_observation <- test[1:3,]
rownames(new_observation) <- c("John Snow", "Arya Stark", "Samwell Tarly")
true_labels <- test[1:3,6]

modelStudio(explainer, new_observation = new_observation,
                       new_observation_y  = true_labels)
```

### grid size

Achieve bigger or smaller `modelStudio` grid with `facet_dim` parameter.

```{r eval = FALSE}
# small dashboard with 2 panels
modelStudio(explainer, new_observation, facet_dim = c(1,2))

# large dashboard with 9 panels
modelStudio(explainer, new_observation, facet_dim = c(3,3))
```

### animations

Manipulate `time` parameter to set animation length. Value 0 will make 
them invisible.

```{r eval = FALSE}
# slow down animations
modelStudio(explainer, new_observation, time = 1000)

# turn off animations
modelStudio(explainer, new_observation, time = 0)
```

### more calculations means more time

`N` is a number of observations used for calculation of partial and accumulated dependence profiles.
`B` is a number of random paths used for calculation of Shapley Values profiles.
Decrease `N` and `B` parameters to lower computation time or increase
them to get more accurate empirical results.

```{r eval = FALSE}
modelStudio(explainer, new_observation, N = 100, B = 10)

modelStudio(explainer, new_observation, N = 1000, B = 50)
```

### no EDA mode

Don't compute the EDA plots if they are not needed. Set the `eda` parameter to `FALSE`.

```{r eval = FALSE}
modelStudio(explainer, new_observation, eda = FALSE)
```

### progress bar

Hide computation progress bar messages with `show_info` parameter.

```{r eval = FALSE}
modelStudio(explainer, new_observation, show_info = FALSE)
```

### viewer or browser?

Change `viewer` parameter to set where to display `modelStudio`. Best described here: [`r2d3 viewer argument`](https://rstudio.github.io/r2d3/articles/visualization_options.html#viewer).

```{r eval = FALSE}
modelStudio(explainer, new_observation, viewer = "browser")
```

-------------------------------------------------------------------

## parallel computation

Speed up `modelStudio` computation by setting `parallel` parameter to `TRUE`. 
It uses [`parallelMap`](https://www.rdocumentation.org/packages/parallelMap) package
to calculate local explainers faster. It is really useful when using `modelStudio` with
complicated models, vast datasets or simply many observations are being processed. 

All options can be set outside of function call.
More on that [here](https://github.com/berndbischl/parallelMap#being-lazy-configuration).

```{r eval = FALSE}
#set up the cluster 
options(
  parallelMap.default.mode        = "socket",
  parallelMap.default.cpus        = 4,
  parallelMap.default.show.info   = FALSE
)

# calculations will be distributed into 4 cores
modelStudio(explainer, new_observation = test[1:16,], parallel = TRUE)
```

--------------------------------------------------------------------

## plot options

Customize some of `modelStudio` looks by overwriting default options returned
by `modelStudioOptions()`.

```{r eval = FALSE}
# set additional graphical parameters
new_options <- modelStudioOptions(
  show_subtitle = TRUE,
  bd_subtitle = "Hello World",
  line_size = 5,
  point_size = 9,
  line_color = "pink",
  point_color = "purple",
  bd_positive_color = "yellow",
  bd_negative_color = "orange" 
)

modelStudio(explainer, new_observation, options = new_options)
```

-------------------------------------------------------------------

## DALEXtra

Use `DALEXtra::explain_*()` functions to explain various models.
Bellow basic example of making `modelStudio` for mlr model using `DALEXtra::explain_mlr()`

```{r eval = FALSE}
library(DALEXtra)
library(mlr)

# fit a model
task <- mlr::makeRegrTask(id = "task",
                          data = train,
                          target = "fired")

learner <- mlr::makeLearner("regr.randomForest",
                            par.vals = list(ntree = 300),
                            predict.type = "response")

model <- mlr::train(learner, task)

# create an explainer for the model
explainer_mlr <- explain_mlr(model,
                             data = test,
                             y = test$fired,
                             label = "mlr")

# make a studio for the model
modelStudio(explainer_mlr, B = 10)
```

## References

* Theoretical introduction to the plots: [Explanatory Model Analysis. Explore, Explain and Examine Predictive Models.](https://pbiecek.github.io/ema)
* Wrapper for the function is implemented in [DALEX](https://modeloriented.github.io/DALEX/)
* Feature Importance, Ceteris Paribus, Partial Dependence and Accumulated Dependence plots 
are implemented in [ingredients](https://modeloriented.github.io/ingredients/)
* Break Down and Shapley Values plots are implemented in [iBreakDown](https://modeloriented.github.io/iBreakDown/)
